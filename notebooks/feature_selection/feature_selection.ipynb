{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from constants import intermediate_names, processed_names\n",
    "import constants.constants as cst\n",
    "from constants.paths import INTERMEDIATE_PC_PRICE_DIR, INTERMEDIATE_PHENOL_ACETONE_DIR\n",
    "from src.data_pipelines.multi_intermediate_to_processed import (\n",
    "    build_multivariate_dataset,\n",
    ")\n",
    "from src.data_pipelines.uni_intermediate_to_processed import build_univariate_dataset\n",
    "import src.utils.feature_engineering as fe_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Analysing intermediate data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_price_eu = pd.read_csv(INTERMEDIATE_PC_PRICE_DIR / \"intermediate_pc_price_eu.csv\")\n",
    "pc_price_eu_grouped = pd.read_csv(\n",
    "    INTERMEDIATE_PC_PRICE_DIR / \"intermediate_pc_price_eu_grouped.csv\"\n",
    ")\n",
    "pc_price_asia = pd.read_csv(\n",
    "    INTERMEDIATE_PC_PRICE_DIR / \"intermediate_pc_price_asia.csv\"\n",
    ")\n",
    "bpa_capacity_loss = pd.read_csv(\n",
    "    INTERMEDIATE_PHENOL_ACETONE_DIR / \"intermediate_bpa_capacity_loss.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_price_asia[\"pc_gf_best_price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Feature Engineering approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "There are 2 approaches to feature engineering depending on the modeling technique we want to use:\n",
    "1. PC type specific models: Use a wide format dataset (1 column per PC type).\n",
    "2. Global multivariate model: Use a long format dataset (1 row per PC type per country per month) with all features included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 1 - PC type specific models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "In this approach, we will create a wide format dataset where each PC type has its own column. Features will be engineered specifically for each PC type. We first create a large dataset with all possible features for each PC type, and select a subset of that dataset at modeling time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "The base dataset is created using the `build_univariate_dataset` function in `src/data_pipelines/uni_intermediate_to_processed.py`. This function simply concatenates all datasets (PC prices and exogenous variables) into a wide format dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df = fe_utils.create_wide_format()\n",
    "wide_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The `asia_pc_gf_best_price` column is weird. Possible that values within the column don't have the same unit. Comes from data, nothing we can really do about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "This is the base for the pipeline that creates the final processed dataset used for modeling in `src/data_pipelines/uni_intermediate_to_processed.py`. The final dataset is built by adding features to the base dataset using functions from `src/utils/feature_engineering.py`.\n",
    "The feature engineering steps are as follows:\n",
    "- Calendar features (month, quarter, year) with cyclical encoding for month and quarter.\n",
    "- Lag features for PC prices.\n",
    "- Rolling window statistics for PC prices.\n",
    "- Rate of change features for PC prices.\n",
    "- Lag features for exogenous variables.\n",
    "- Rolling window statistics for exogenous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "This is the base for the pipeline that creates the final processed dataset used for modeling in `src/data_pipelines/uni_intermediate_to_processed.py`. The final dataset is built by adding features to the base dataset using functions from `src/utils/feature_engineering.py`.\n",
    "The feature engineering steps are as follows:\n",
    "- Calendar features (month, quarter, year) with cyclical encoding for month and quarter.\n",
    "- Lag features for PC prices.\n",
    "- Rolling window statistics for PC prices.\n",
    "- Rate of change features for PC prices.\n",
    "- Lag features for exogenous variables.\n",
    "- Rolling window statistics for exogenous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_wide_df = build_univariate_dataset(horizon=3)\n",
    "full_wide_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Once this dataset is created, we can select the relevant columns for each PC type and use it for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(wide_df: pd.DataFrame, pc_type: cst.PCType) -> pd.DataFrame:\n",
    "    \"\"\"Select relevant features for the univariate model for the selected PC type.\n",
    "\n",
    "    These features include:\n",
    "\n",
    "    Args:\n",
    "        wide_df (pd.DataFrame): The full wide format dataframe\n",
    "        pc_type (PCType): The name of the PC type to select features for\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe containing only the relevant features for the\n",
    "        specified PC type.\n",
    "    \"\"\"\n",
    "    if not isinstance(pc_type, cst.PCType):\n",
    "        raise ValueError(\n",
    "            f\"pc_type must be an instance of {cst.PCType} Enum, got {type(pc_type)}\"\n",
    "        )\n",
    "    pc_type_columns = [col for col in wide_df.columns if pc_type.value in col]\n",
    "\n",
    "    exogenous_features = []\n",
    "    for exogenous_col in intermediate_names.EXOGENOUS_COLUMNS:\n",
    "        exogenous_features.extend(\n",
    "            [\n",
    "                col\n",
    "                for col in wide_df.columns\n",
    "                if (pc_type.name not in col and exogenous_col in col)\n",
    "            ]\n",
    "        )\n",
    "    relevant_features = (\n",
    "        pc_type_columns + exogenous_features + [processed_names.WIDE_DATE]\n",
    "    )\n",
    "    return wide_df[relevant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features(wide_df=full_wide_df, pc_type=cst.PCType.CRYSTAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 2 - Global multivariate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "In this approach , we will create a long format dataset where each row corresponds to a specific PC type in a specific region at a specific month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "```\n",
    "| date       | region | pc_type | price | ... features ... |\n",
    "|------------|--------|---------|-------|------------------|\n",
    "| 2020-01-01 | europe | crystal | 2.5   | ...              |\n",
    "| 2020-01-01 | europe | gf10    | 2.8   | ...              |\n",
    "| 2020-01-01 | asia   | gp      | 2.3   | ...              |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = fe_utils.create_long_format()\n",
    "long_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df[long_df[\"region\"] == \"europe\"][\"pc_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df[long_df[\"pc_type\"] == \"gf\"][\"pc_price\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distributions by PC type\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Europe\n",
    "eu_data = long_df[long_df[processed_names.LONG_REGION] == cst.EUROPE]\n",
    "eu_data.boxplot(\n",
    "    column=processed_names.LONG_PC_PRICE, by=processed_names.LONG_PC_TYPE, ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Europe PC Price Distributions\")\n",
    "axes[0].set_xlabel(\"PC Type\")\n",
    "axes[0].set_ylabel(\"Price (USD/kg)\")\n",
    "plt.sca(axes[0])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Asia\n",
    "asia_data = long_df[long_df[processed_names.LONG_REGION] == cst.ASIA]\n",
    "asia_data.boxplot(\n",
    "    column=processed_names.LONG_PC_PRICE, by=processed_names.LONG_PC_TYPE, ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Asia PC Price Distributions\")\n",
    "axes[1].set_xlabel(\"PC Type\")\n",
    "axes[1].set_ylabel(\"Price (USD/kg)\")\n",
    "plt.sca(axes[1])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced data across PC types\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Europe\n",
    "eu_data = long_df[long_df[processed_names.LONG_REGION] == cst.EUROPE]\n",
    "eu_counts = (\n",
    "    eu_data[processed_names.LONG_PC_TYPE].value_counts().sort_values(ascending=False)\n",
    ")\n",
    "axes[0].bar(range(len(eu_counts)), eu_counts.values)\n",
    "axes[0].set_xticks(range(len(eu_counts)))\n",
    "axes[0].set_xticklabels(eu_counts.index, rotation=45, ha=\"right\")\n",
    "axes[0].set_title(\"Europe: Number of Samples per PC Type\")\n",
    "axes[0].set_xlabel(\"PC Type\")\n",
    "axes[0].set_ylabel(\"Number of Samples\")\n",
    "\n",
    "# Asia\n",
    "asia_data = long_df[long_df[processed_names.LONG_REGION] == cst.ASIA]\n",
    "asia_counts = (\n",
    "    asia_data[processed_names.LONG_PC_TYPE].value_counts().sort_values(ascending=False)\n",
    ")\n",
    "axes[1].bar(range(len(asia_counts)), asia_counts.values)\n",
    "axes[1].set_xticks(range(len(asia_counts)))\n",
    "axes[1].set_xticklabels(asia_counts.index, rotation=45, ha=\"right\")\n",
    "axes[1].set_title(\"Asia: Number of Samples per PC Type\")\n",
    "axes[1].set_xlabel(\"PC Type\")\n",
    "axes[1].set_ylabel(\"Number of Samples\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_long_df = build_multivariate_dataset(horizon=3)\n",
    "full_long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag feature correlation with target (by PC type)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "lag_cols = [c for c in full_long_df.columns if \"pc_price_lag\" in c]\n",
    "corr_by_type = (\n",
    "    full_long_df.groupby(processed_names.LONG_PC_TYPE)[\n",
    "        [processed_names.LONG_PC_PRICE] + lag_cols\n",
    "    ]\n",
    "    .corr()[processed_names.LONG_PC_PRICE]\n",
    "    .drop(processed_names.LONG_PC_PRICE, level=1)\n",
    ")\n",
    "\n",
    "corr_by_type.unstack().T.plot(kind=\"bar\", ax=ax)\n",
    "ax.set_title(\"Lag Feature Correlations with Target Price (by PC Type)\")\n",
    "ax.set_xlabel(\"Lag Feature\")\n",
    "ax.set_ylabel(\"Correlation with Price\")\n",
    "ax.legend(title=\"PC Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Feature selection rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "14-data-challenge (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
