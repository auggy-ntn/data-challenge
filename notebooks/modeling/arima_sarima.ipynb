{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Modeling SARIMA par PCType / région (multi_3m)\n",
    "Prévision mensuelle de `pc_price` par PCType/région avec SARIMA, split hold-out pour MAPE et option MLflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Imports et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import constants.constants as cst\n",
    "from constants.paths import PROCESSED_DATA_DIR\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 4)\n",
    "\n",
    "DATA_PATH = PROCESSED_DATA_DIR / \"multi_3m.csv\"\n",
    "assert DATA_PATH.exists(), DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Configurer MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "if tracking_uri:\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    print(f\"Tracking URI: {tracking_uri}\")\n",
    "\n",
    "experiment_id = os.getenv(\"MLFLOW_EXPERIMENT_ID\")\n",
    "experiment_name = os.getenv(\"MLFLOW_EXPERIMENT_NAME\")\n",
    "active_experiment_id = experiment_id\n",
    "\n",
    "if experiment_name:\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if exp and not active_experiment_id:\n",
    "        active_experiment_id = exp.experiment_id\n",
    "    print(\"Experiment name:\", experiment_name)\n",
    "\n",
    "if active_experiment_id:\n",
    "    print(\"Using experiment_id:\", active_experiment_id)\n",
    "else:\n",
    "    print(\"No experiment_id provided; runs will use the active/default experiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(horizon: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Load multi_{horizon}m.csv and sort.\"\"\"\n",
    "    df_local = pd.read_csv(\n",
    "        PROCESSED_DATA_DIR / f\"multi_{horizon}m.csv\", parse_dates=[\"date\"]\n",
    "    )\n",
    "    return df_local.sort_values([\"pc_type\", \"region\", \"date\"])\n",
    "\n",
    "\n",
    "df = load_data(3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Disponibilité des PCType (Enum vs données)\n",
    "\n",
    "Vérifie quelles valeurs de `PCType` existent dans les données processees et le coverage par région."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.constants import PCType\n",
    "\n",
    "pc_enum = [p.value for p in PCType]\n",
    "pc_seen = sorted(df.pc_type.unique())\n",
    "counts = (\n",
    "    df.groupby([\"pc_type\", \"region\"])\n",
    "    .agg(start=(\"date\", \"min\"), end=(\"date\", \"max\"), rows=(\"date\", \"size\"))\n",
    "    .reset_index()\n",
    ")\n",
    "missing_enum = [p for p in pc_enum if p not in pc_seen]\n",
    "print(\"PCType vus dans les données:\", pc_seen)\n",
    "print(\"PCType Enum manquants dans les données:\", missing_enum)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Fonction MAPE\n",
    "Utilisée pour les baselines et SARIMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true: pd.Series, y_pred: pd.Series) -> float | None:\n",
    "    \"\"\"MAPE fraction (pas de *100), en ignorant zéros/NaN.\"\"\"\n",
    "    mask = (y_true != 0) & y_true.notna() & y_pred.notna()\n",
    "    if mask.sum() == 0:\n",
    "        return None\n",
    "    return (np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Métriques alignées avec global_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(df_slice: pd.DataFrame, preds: pd.Series) -> dict:\n",
    "    \"\"\"Retourne global_mape, weighted_mape et mape par pc_type.\"\"\"\n",
    "    metrics: dict[str, float | None] = {}\n",
    "    y_true = df_slice[\"pc_price\"]\n",
    "    metric_val = mape(y_true, preds)\n",
    "    metrics[cst.GLOBAL_MAPE] = metric_val\n",
    "    metrics[cst.WEIGHTED_MAPE] = metric_val\n",
    "    for pc_val, grp in df_slice.groupby(\"pc_type\"):\n",
    "        metrics[f\"{pc_val}_mape\"] = mape(grp[\"pc_price\"], preds.loc[grp.index])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Baselines MAPE par horizon (naïf et saisonnier t-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_mape(\n",
    "    horizon: int,\n",
    "    strategy: str = \"naive\",\n",
    "    df_full: pd.DataFrame | None = None,\n",
    "    test_df: pd.DataFrame | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute naïf/saisonnier MAPE par pc_type/region (fraction).\"\"\"\n",
    "    rows = []\n",
    "    data = df_full if df_full is not None else df\n",
    "    for (pc, reg), g in data.groupby([\"pc_type\", \"region\"]):\n",
    "        g = g.sort_values(\"date\").set_index(\"date\")\n",
    "        y = g[\"pc_price\"]\n",
    "        if strategy == \"naive\":\n",
    "            pred = y.shift(horizon)\n",
    "        elif strategy == \"seasonal_naive\":\n",
    "            pred = y.shift(12)\n",
    "        else:\n",
    "            raise ValueError(\"strategy must be naive or seasonal_naive\")\n",
    "        if test_df is not None:\n",
    "            mask_dates = test_df[(test_df.pc_type == pc) & (test_df.region == reg)][\n",
    "                \"date\"\n",
    "            ]\n",
    "            test_mask = g.index.isin(mask_dates)\n",
    "            m = mape(y[test_mask], pred[test_mask])\n",
    "        else:\n",
    "            m = mape(y, pred)\n",
    "        rows.append(\n",
    "            {\n",
    "                \"pc_type\": pc,\n",
    "                \"region\": reg,\n",
    "                \"horizon\": horizon,\n",
    "                \"strategy\": strategy,\n",
    "                \"MAPE\": m,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Split temporel adaptatif\n",
    "Assure un minimum d'observations train/test par (pc_type, region)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_train_test_split(\n",
    "    df_local: pd.DataFrame,\n",
    "    group_cols: list[str],\n",
    "    target_test_ratio: float = 0.2,\n",
    "    min_train_samples: int = 20,\n",
    "    min_test_samples: int = 5,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split temporel garantissant un minimum par groupe.\"\"\"\n",
    "    df_local = df_local.sort_values(\"date\").reset_index(drop=True)\n",
    "    dates = sorted(df_local[\"date\"].unique())\n",
    "    unique_groups = df_local[group_cols].drop_duplicates().to_dict(\"records\")\n",
    "    for split_date in reversed(dates):\n",
    "        train = df_local[df_local[\"date\"] < split_date]\n",
    "        test = df_local[df_local[\"date\"] >= split_date]\n",
    "        valid = True\n",
    "        for g in unique_groups:\n",
    "            train_g = train\n",
    "            test_g = test\n",
    "            for col, val in g.items():\n",
    "                train_g = train_g[train_g[col] == val]\n",
    "                test_g = test_g[test_g[col] == val]\n",
    "            if len(train_g) < min_train_samples or len(test_g) < min_test_samples:\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            print(f\"Found valid global split at date: {split_date}\")\n",
    "            return train, test\n",
    "    print(\"No valid global split found. Falling back to ratio.\")\n",
    "    split_idx = int(len(dates) * (1 - target_test_ratio))\n",
    "    split_date = dates[split_idx]\n",
    "    return df_local[df_local[\"date\"] < split_date], df_local[\n",
    "        df_local[\"date\"] >= split_date\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Baselines sur le jeu de validation (test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {}\n",
    "baseline_tables = []\n",
    "for horizon in [3, 6, 9]:\n",
    "    df_h = load_data(horizon)\n",
    "    train_df_h, test_df_h = adaptive_train_test_split(\n",
    "        df_h,\n",
    "        group_cols=[\"pc_type\", \"region\"],\n",
    "        target_test_ratio=0.2,\n",
    "        min_train_samples=20,\n",
    "        min_test_samples=5,\n",
    "    )\n",
    "    splits[horizon] = {\"df\": df_h, \"train\": train_df_h, \"test\": test_df_h}\n",
    "    baseline_tables.append(\n",
    "        baseline_mape(horizon, \"naive\", df_full=df_h, test_df=test_df_h)\n",
    "    )\n",
    "    baseline_tables.append(\n",
    "        baseline_mape(horizon, \"seasonal_naive\", df_full=df_h, test_df=test_df_h)\n",
    "    )\n",
    "baseline_df = pd.concat(baseline_tables, ignore_index=True)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## SARIMA + logging MLflow (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sarima(\n",
    "    pc_type: str,\n",
    "    region: str,\n",
    "    df_source: pd.DataFrame,\n",
    "    order: tuple[int, int, int] = (1, 1, 0),\n",
    "    seasonal_order: tuple[int, int, int, int] = (0, 0, 0, 12),\n",
    "    horizon: int = 6,\n",
    "    train_df: pd.DataFrame | None = None,\n",
    "    test_df: pd.DataFrame | None = None,\n",
    ") -> dict:\n",
    "    \"\"\"Fit SARIMA pour un pc_type/region et retourne métriques.\"\"\"\n",
    "    train_slice = (\n",
    "        train_df[(train_df.pc_type == pc_type) & (train_df.region == region)]\n",
    "        if train_df is not None\n",
    "        else df_source[(df_source.pc_type == pc_type) & (df_source.region == region)]\n",
    "    )\n",
    "    test_slice = (\n",
    "        test_df[(test_df.pc_type == pc_type) & (test_df.region == region)]\n",
    "        if test_df is not None\n",
    "        else None\n",
    "    )\n",
    "    train_slice = train_slice.sort_values(\"date\")\n",
    "    y_train = train_slice.set_index(\"date\")[\"pc_price\"]\n",
    "    if test_slice is not None and not test_slice.empty:\n",
    "        y_test = test_slice.sort_values(\"date\").set_index(\"date\")[\"pc_price\"]\n",
    "    else:\n",
    "        return {\n",
    "            \"pc_type\": pc_type,\n",
    "            \"region\": region,\n",
    "            \"MAPE\": None,\n",
    "            \"n_points\": 0,\n",
    "            \"note\": \"Test set empty (strict split)\",\n",
    "        }\n",
    "    if len(y_train) <= max(order[0], seasonal_order[0] * seasonal_order[3]):\n",
    "        return {\n",
    "            \"pc_type\": pc_type,\n",
    "            \"region\": region,\n",
    "            \"MAPE\": None,\n",
    "            \"n_points\": 0,\n",
    "            \"note\": \"train trop court\",\n",
    "        }\n",
    "    try:\n",
    "        model = SARIMAX(\n",
    "            y_train,\n",
    "            order=order,\n",
    "            seasonal_order=seasonal_order,\n",
    "            enforce_stationarity=False,\n",
    "            enforce_invertibility=False,\n",
    "        )\n",
    "        res = model.fit(disp=False)\n",
    "        steps = min(len(y_test), horizon)\n",
    "        fc = res.get_forecast(steps=steps).predicted_mean\n",
    "        m = mape(y_test.iloc[:steps], fc)\n",
    "        return {\n",
    "            \"pc_type\": pc_type,\n",
    "            \"region\": region,\n",
    "            \"MAPE\": m,\n",
    "            \"order\": order,\n",
    "            \"seasonal_order\": seasonal_order,\n",
    "            \"horizon\": horizon,\n",
    "            \"n_points\": steps,\n",
    "        }\n",
    "    except Exception as exc:\n",
    "        return {\n",
    "            \"pc_type\": pc_type,\n",
    "            \"region\": region,\n",
    "            \"MAPE\": None,\n",
    "            \"n_points\": 0,\n",
    "            \"error\": str(exc),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = []\n",
    "agg_rows = []\n",
    "for horizon, objs in splits.items():\n",
    "    df_h = objs[\"df\"]\n",
    "    train_h = objs[\"train\"]\n",
    "    test_h = objs[\"test\"]\n",
    "    horizon_results = []\n",
    "    for pc in sorted(df_h.pc_type.unique()):\n",
    "        for reg in sorted(df_h.region.unique()):\n",
    "            res = evaluate_sarima(\n",
    "                pc, reg, df_h, horizon=horizon, train_df=train_h, test_df=test_h\n",
    "            )\n",
    "            res[\"horizon\"] = horizon\n",
    "            horizon_results.append(res)\n",
    "    if horizon_results:\n",
    "        hr_df = pd.DataFrame(horizon_results)\n",
    "        results_all.append(hr_df)\n",
    "        valid = hr_df[hr_df[\"MAPE\"].notna()].copy()\n",
    "        if not valid.empty:\n",
    "            weights = valid[\"n_points\"].replace(0, 1)\n",
    "\n",
    "            def wmean(series, weights=weights):\n",
    "                \"\"\"Compute weighted mean, using weights from the closure.\"\"\"\n",
    "                return float(np.average(series, weights=weights.loc[series.index]))\n",
    "\n",
    "            agg = {\n",
    "                \"horizon\": horizon,\n",
    "                cst.GLOBAL_MAPE: wmean(valid[\"MAPE\"]),\n",
    "                cst.WEIGHTED_MAPE: wmean(valid[\"MAPE\"]),\n",
    "            }\n",
    "            reg_subset = valid[valid[\"pc_type\"] == cst.REGULAR_PC_TYPE]\n",
    "            if not reg_subset.empty:\n",
    "                agg[\"regular_mape\"] = wmean(reg_subset[\"MAPE\"])\n",
    "            green_subset = valid[valid[\"pc_type\"] == cst.GREEN_PC_TYPE]\n",
    "            if not green_subset.empty:\n",
    "                agg[\"green_mape\"] = wmean(green_subset[\"MAPE\"])\n",
    "            agg_rows.append(agg)\n",
    "\n",
    "results_df = (\n",
    "    pd.concat(results_all, ignore_index=True) if results_all else pd.DataFrame()\n",
    ")\n",
    "\n",
    "agg_df = pd.DataFrame(agg_rows) if agg_rows else pd.DataFrame()\n",
    "\n",
    "# MLflow logging par horizon (désactivé par défaut)\n",
    "log_horizon_mlflow = True\n",
    "if log_horizon_mlflow and not agg_df.empty:\n",
    "    for _, row in agg_df.iterrows():\n",
    "        h = int(row[\"horizon\"])\n",
    "        metrics_to_log = {\n",
    "            k: v for k, v in row.items() if k != \"horizon\" and pd.notna(v)\n",
    "        }\n",
    "        with mlflow.start_run(\n",
    "            run_name=f\"SARIMA_agg_h{h}\", experiment_id=active_experiment_id\n",
    "        ):\n",
    "            mlflow.set_tags(\n",
    "                {\n",
    "                    cst.MLFLOW_MODEL_TYPE: \"sarima\",\n",
    "                    cst.MLFLOW_MODEL_PHILOSOPHY: \"statistical\",\n",
    "                    cst.MLFLOW_FUNCTION: \"forecast\",\n",
    "                    cst.MLFLOW_HORIZON: h,\n",
    "                }\n",
    "            )\n",
    "            mlflow.log_metrics(metrics_to_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Run diagnostic (sans logging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "(Per-série MLflow logging désactivé)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "14-data-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
