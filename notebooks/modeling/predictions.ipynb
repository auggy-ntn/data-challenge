{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook is used to make predictions on data using the models trained in `global_model_training.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to retrieve the correct model from MLflow\n",
    "horizon = 3\n",
    "function = \"prediction\"\n",
    "group_by_pc_types = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from constants import processed_names\n",
    "from constants.paths import SE_PREDICTIONS_DATA_DIR\n",
    "from src.modeling.multivariate_data_prep import (\n",
    "    load_and_prepare_data,\n",
    ")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# 1. Load Predictions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_preds = pd.read_csv(SE_PREDICTIONS_DATA_DIR / \"se_predictions_uni.csv\")\n",
    "uni_grouped_preds = pd.read_csv(\n",
    "    SE_PREDICTIONS_DATA_DIR / \"se_predictions_uni_grouped.csv\"\n",
    ")\n",
    "\n",
    "multi_preds = pd.read_csv(SE_PREDICTIONS_DATA_DIR / \"se_predictions_multi.csv\")\n",
    "multi_grouped_preds = pd.read_csv(\n",
    "    SE_PREDICTIONS_DATA_DIR / \"se_predictions_multi_grouped.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# 2. Load prediciton models from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow_runs = mlflow.search_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow_runs[\n",
    "#     (mlflow_runs[\"tags.horizon\"] == str(horizon))\n",
    "#     & (mlflow_runs[\"tags.function\"] == function)\n",
    "#     & (mlflow_runs[\"tags.grouped_by_pc_types\"] == str(group_by_pc_types))\n",
    "# ][[\"run_id\", \"tags.mlflow.runName\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3m_uri = \"models:/m-3c0554ecaddb4f1fafe1e6c3c3070e6b\"  # XGBoost\n",
    "# model_3m_uri = \"models:/m-7e484d84f5254e2082d2d740a77c653c\"  # Catboost\n",
    "# model_3m_uri = \"models:/m-e28aaa81fc834123a7fc7486a9db66ae\"  # RandomForest\n",
    "# model_3m_uri = \"models:/m-964efc13017646d5830bd89454d26715\"  # LightGBM\n",
    "model_3m = mlflow.pyfunc.load_model(model_3m_uri)\n",
    "\n",
    "model_6m_uri = \"models:/m-ef1ddec2cfc845fb94ca9d7ca4533fc9\"  # XGBoost\n",
    "# model_6m_uri = \"models:/m-83edac81cd0649bf81cb7253dc621053\"  # Catboost\n",
    "# model_6m_uri = \"models:/m-d2b4272168054f449fc03924417d5028\"  # RandomForest\n",
    "# model_6m_uri = \"models:/m-6b45c3ca975743e5b2593f99e1125aff\"  # LightGBM\n",
    "model_6m = mlflow.pyfunc.load_model(model_6m_uri)\n",
    "\n",
    "model_9m_uri = \"models:/m-8cd9199c03b743d5b57592c5c55f275c\"  # XGBoost\n",
    "# model_9m_uri = \"models:/m-568b5a45ea9a4ef78580c4435f4c1c2f\"  # Catboost\n",
    "# model_9m_uri = \"models:/m-b2bf0b210964424f92f08989635efd0d\"  # RandomForest\n",
    "# model_9m_uri = \"models:/m-347e3f10db3840a0b45e43b2b00f24c8\"  # LightGBM\n",
    "model_9m = mlflow.pyfunc.load_model(model_9m_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# 3. Prepare Data for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target_col, feature_cols, mappings_dict = load_and_prepare_data(\n",
    "    group_by_pc_types=group_by_pc_types, horizon=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# 4. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_predict_pc_prices(\n",
    "    model: Any,\n",
    "    horizon: int,\n",
    "    group_by_pc_types: bool,\n",
    "    data_date: str,\n",
    "    target_date: str,\n",
    "    predictions_df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Make predictions for PC prices and compare with SE predicted prices.\n",
    "\n",
    "    Args:\n",
    "        model: Trained MLflow model for making predictions.\n",
    "        horizon: Prediction horizon in months.\n",
    "        group_by_pc_types: Whether to group data by PC types.\n",
    "        data_date: Date string representing the date of the input features.\n",
    "        target_date: Date string representing the date for which predictions are made.\n",
    "        predictions_df: DataFrame containing actual prices for comparison.\n",
    "\n",
    "    Returns: DataFrame with predicted and actual prices grouped by PC type.\n",
    "    \"\"\"\n",
    "    data, _, feature_cols, _ = load_and_prepare_data(\n",
    "        group_by_pc_types=group_by_pc_types, horizon=horizon\n",
    "    )\n",
    "    # Filter data and reset index before prediction\n",
    "    data_filtered = data[data[processed_names.LONG_DATE] == data_date][\n",
    "        feature_cols\n",
    "    ].reset_index(drop=True)\n",
    "    preds = model.predict(data_filtered)\n",
    "\n",
    "    results_df = data[data[processed_names.LONG_DATE] == data_date][\n",
    "        [\n",
    "            processed_names.LONG_DATE,\n",
    "            processed_names.LONG_PC_TYPE,\n",
    "            processed_names.LONG_REGION,\n",
    "        ]\n",
    "    ].copy()\n",
    "    results_df[\"target_date\"] = target_date\n",
    "    results_df[\"predicted_price\"] = preds\n",
    "    results_df[\"actual_price\"] = predictions_df[\n",
    "        predictions_df[processed_names.LONG_DATE] == target_date\n",
    "    ][processed_names.LONG_PC_PRICE].values\n",
    "\n",
    "    # results_df = results_df.groupby(processed_names.LONG_PC_TYPE).agg(\n",
    "    #     {\"predicted_price\": \"min\", \"actual_price\": \"min\"}\n",
    "    # )\n",
    "    results_df[\"date\"] = target_date\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_predict_pc_prices(\n",
    "#     model=model_6m,\n",
    "#     horizon=6,\n",
    "#     group_by_pc_types=False,\n",
    "#     data_date=\"2025-04-01\",\n",
    "#     target_date=\"2025-10-01\",\n",
    "#     predictions_df=multi_preds,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_predict_all_pc_prices(\n",
    "    group_by_pc_types: bool, predictions: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Make predictions for all PC prices from July to December 2025.\n",
    "\n",
    "    Args:\n",
    "        group_by_pc_types: Whether to group data by PC types.\n",
    "        predictions: DataFrame containing actual prices for comparison.\n",
    "\n",
    "    Returns: DataFrame with predicted and actual prices for all PCs from\n",
    "             July to December 2025.\n",
    "    \"\"\"\n",
    "    full_results_df = pd.DataFrame()\n",
    "    for i in range(7, 10):\n",
    "        # Use best 3 month model to predict prices for July, August, September\n",
    "        data_date = f\"2025-0{i - 3}-01\"\n",
    "        target_date = f\"2025-0{i}-01\"\n",
    "        results_df = multi_predict_pc_prices(\n",
    "            model=model_3m,\n",
    "            horizon=3,\n",
    "            group_by_pc_types=group_by_pc_types,\n",
    "            data_date=data_date,\n",
    "            target_date=target_date,\n",
    "            predictions_df=predictions,\n",
    "        )\n",
    "        full_results_df = pd.concat([full_results_df, results_df], axis=0)\n",
    "\n",
    "    for i in range(10, 13):\n",
    "        # Use best 6 month model to predict prices for October, November, December\n",
    "        data_date = f\"2025-0{i - 6}-01\"\n",
    "        target_date = f\"2025-{i}-01\"\n",
    "        results_df = multi_predict_pc_prices(\n",
    "            model=model_6m,\n",
    "            horizon=6,\n",
    "            group_by_pc_types=group_by_pc_types,\n",
    "            data_date=data_date,\n",
    "            target_date=target_date,\n",
    "            predictions_df=predictions,\n",
    "        )\n",
    "        full_results_df = pd.concat([full_results_df, results_df], axis=0)\n",
    "\n",
    "    for i in range(1, 4):\n",
    "        # Use best 9 months model to predict January, February, March\n",
    "        data, _, feature_cols, _ = load_and_prepare_data(\n",
    "            group_by_pc_types=group_by_pc_types, horizon=9\n",
    "        )\n",
    "        data_date = f\"2025-0{i + 3}-01\"\n",
    "        target_date = f\"2026-0{i}-01\"\n",
    "\n",
    "        preds = model_9m.predict(\n",
    "            data[data[processed_names.LONG_DATE] == data_date][feature_cols]\n",
    "        )\n",
    "\n",
    "        results_df = pd.DataFrame(columns=full_results_df.columns)\n",
    "        results_df[\"predicted_price\"] = preds\n",
    "        results_df[processed_names.LONG_DATE] = target_date\n",
    "        results_df[processed_names.LONG_PC_TYPE] = data[\n",
    "            data[processed_names.LONG_DATE] == data_date\n",
    "        ][processed_names.LONG_PC_TYPE].values\n",
    "\n",
    "        full_results_df = pd.concat([full_results_df, results_df], axis=0)\n",
    "\n",
    "    return full_results_df.groupby(\n",
    "        [processed_names.LONG_DATE, processed_names.LONG_PC_TYPE]\n",
    "    ).agg({\"predicted_price\": \"min\", \"actual_price\": \"min\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = multi_predict_all_pc_prices(\n",
    "    group_by_pc_types=group_by_pc_types, predictions=multi_preds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# 5. Visualize Predictions vs Actual Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization dataframe\n",
    "# 1. Get actual data up to 2025-06\n",
    "actual_data = (\n",
    "    data[data[processed_names.LONG_DATE] <= \"2025-06-01\"]\n",
    "    .groupby([processed_names.LONG_DATE, processed_names.LONG_PC_TYPE])\n",
    "    .agg({\"pc_price\": \"min\"})\n",
    ")\n",
    "actual_data = actual_data.rename(columns={processed_names.LONG_PC_PRICE: \"actual\"})\n",
    "\n",
    "# 2. Get SE forecasts for 2025-07 to 2025-12\n",
    "se_forecast_data = comparison_df[\n",
    "    (comparison_df.index.get_level_values(processed_names.LONG_DATE) >= \"2025-07-01\")\n",
    "    & (comparison_df.index.get_level_values(processed_names.LONG_DATE) <= \"2025-12-01\")\n",
    "][[\"actual_price\"]].rename(columns={\"actual_price\": \"se_forecast\"})\n",
    "\n",
    "# 3. Get our forecasts for 2025-07 to 2026-03\n",
    "our_forecast_data = comparison_df[\n",
    "    (comparison_df.index.get_level_values(processed_names.LONG_DATE) >= \"2025-07-01\")\n",
    "    & (comparison_df.index.get_level_values(processed_names.LONG_DATE) <= \"2026-03-01\")\n",
    "][[\"predicted_price\"]].rename(columns={\"predicted_price\": \"our_forecast\"})\n",
    "\n",
    "# Combine all data\n",
    "viz_df = actual_data.join(se_forecast_data, how=\"outer\").join(\n",
    "    our_forecast_data, how=\"outer\"\n",
    ")\n",
    "viz_df = viz_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_forecasts_vs_actual(\n",
    "    viz_df: pd.DataFrame, forecast_start_date: str = \"2025-07-01\"\n",
    "):\n",
    "    \"\"\"Plot actual data, our forecasts, and SE forecasts.\n",
    "\n",
    "    Args:\n",
    "        viz_df: DataFrame with columns: date, pc_type, actual, se_forecast, our_forecast\n",
    "        forecast_start_date: Date where forecasts begin (default: \"2025-07-01\")\n",
    "    \"\"\"\n",
    "    # Create separate figures for each PC type\n",
    "    pc_types = sorted(viz_df[\"pc_type\"].unique())\n",
    "    forecast_date = pd.to_datetime(forecast_start_date)\n",
    "\n",
    "    for pc_type in pc_types:\n",
    "        # Create a new figure for each PC type\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "        # Filter data for this PC type\n",
    "        pc_data = viz_df[viz_df[\"pc_type\"] == pc_type].copy()\n",
    "        pc_data[\"date\"] = pd.to_datetime(pc_data[\"date\"])\n",
    "        pc_data = pc_data.sort_values(\"date\")\n",
    "\n",
    "        # Plot actual data\n",
    "        actual_mask = pc_data[\"actual\"].notna()\n",
    "        ax.plot(\n",
    "            pc_data[actual_mask][\"date\"],\n",
    "            pc_data[actual_mask][\"actual\"],\n",
    "            marker=\"o\",\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            label=\"Actual\",\n",
    "            color=\"#003A70\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        # Plot SE forecast\n",
    "        se_mask = pc_data[\"se_forecast\"].notna()\n",
    "        ax.plot(\n",
    "            pc_data[se_mask][\"date\"],\n",
    "            pc_data[se_mask][\"se_forecast\"],\n",
    "            marker=\"o\",\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            label=\"SE Forecast\",\n",
    "            color=\"#3CC956\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        # Plot our forecast\n",
    "        our_mask = pc_data[\"our_forecast\"].notna()\n",
    "        ax.plot(\n",
    "            pc_data[our_mask][\"date\"],\n",
    "            pc_data[our_mask][\"our_forecast\"],\n",
    "            marker=\"o\",\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            label=\"Our Forecast\",\n",
    "            color=\"#F10101\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        # Add vertical line at forecast start\n",
    "        ax.axvline(\n",
    "            x=forecast_date,\n",
    "            color=\"#000000\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=1,\n",
    "            label=\"Forecast Start\",\n",
    "            alpha=1,\n",
    "        )\n",
    "\n",
    "        # Formatting\n",
    "        ax.set_xlabel(\"Date\", fontsize=12)\n",
    "        ax.set_ylabel(\"PC Price\", fontsize=12)\n",
    "        ax.set_title(\n",
    "            f\"PC Price Forecasts:Actual vs SE vs Our Model - {pc_type.capitalize()} PC\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        ax.legend(fontsize=10, loc=\"best\")\n",
    "        ax.grid(True, alpha=0.3, linestyle=\"--\")\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        # Format x-axis to show dates nicely\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasts_vs_actual(viz_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "14-data-challenge (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
