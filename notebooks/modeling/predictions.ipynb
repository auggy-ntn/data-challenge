{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook is used to make predictions on data using the models trained in `global_model_training.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to retrieve the correct model from MLflow\n",
    "horizon = 3\n",
    "function = \"prediction\"\n",
    "group_by_pc_types = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from constants import processed_names\n",
    "from constants.paths import SE_PREDICTIONS_DATA_DIR\n",
    "from src.modeling.multivariate_data_prep import (\n",
    "    load_and_prepare_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# 1. Load Predictions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_preds = pd.read_csv(SE_PREDICTIONS_DATA_DIR / \"se_predictions_uni.csv\")\n",
    "uni_grouped_preds = pd.read_csv(\n",
    "    SE_PREDICTIONS_DATA_DIR / \"se_predictions_uni_grouped.csv\"\n",
    ")\n",
    "\n",
    "multi_preds = pd.read_csv(SE_PREDICTIONS_DATA_DIR / \"se_predictions_multi.csv\")\n",
    "multi_grouped_preds = pd.read_csv(\n",
    "    SE_PREDICTIONS_DATA_DIR / \"se_predictions_multi_grouped.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# 2. Load prediciton models from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_runs = mlflow.search_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_runs[\n",
    "    (mlflow_runs[\"tags.horizon\"] == str(horizon))\n",
    "    & (mlflow_runs[\"tags.function\"] == function)\n",
    "    & (mlflow_runs[\"tags.grouped_by_pc_types\"] == str(group_by_pc_types))\n",
    "][[\"run_id\", \"tags.mlflow.runName\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3m_uri = \"models:/m-7e484d84f5254e2082d2d740a77c653c\"\n",
    "model_3m = mlflow.pyfunc.load_model(model_3m_uri)\n",
    "\n",
    "model_6m_uri = \"models:/m-83edac81cd0649bf81cb7253dc621053\"\n",
    "model_6m = mlflow.pyfunc.load_model(model_6m_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# 3. Prepare Data for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target_col, feature_cols, mappings_dict = load_and_prepare_data(\n",
    "    group_by_pc_types=group_by_pc_types, horizon=horizon\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# 4. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_predict_pc_prices(\n",
    "    model: Any,\n",
    "    data_df: pd.DataFrame,\n",
    "    feature_cols: list[str],\n",
    "    data_date: str,\n",
    "    target_date: str,\n",
    "    predictions_df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Make predictions for PC prices and compare with SE predicted prices.\n",
    "\n",
    "    Args:\n",
    "        model: Trained MLflow model for making predictions.\n",
    "        data_df: DataFrame containing the features for prediction.\n",
    "        feature_cols: List of feature column names to be used for prediction.\n",
    "        data_date: Date string representing the date of the input features.\n",
    "        target_date: Date string representing the date for which predictions are made.\n",
    "        predictions_df: DataFrame containing actual prices for comparison.\n",
    "\n",
    "    Returns: DataFrame with predicted and actual prices grouped by PC type.\n",
    "    \"\"\"\n",
    "    preds = model.predict(\n",
    "        data_df[data_df[processed_names.LONG_DATE] == data_date][feature_cols]\n",
    "    )\n",
    "    results_df = data_df[data_df[processed_names.LONG_DATE] == data_date][\n",
    "        [\n",
    "            processed_names.LONG_DATE,\n",
    "            processed_names.LONG_PC_TYPE,\n",
    "            processed_names.LONG_REGION,\n",
    "        ]\n",
    "    ].copy()\n",
    "    results_df[\"target_date\"] = target_date\n",
    "    results_df[\"predicted_price\"] = preds\n",
    "    results_df[\"actual_price\"] = predictions_df[\n",
    "        predictions_df[processed_names.LONG_DATE] == target_date\n",
    "    ][processed_names.LONG_PC_PRICE].values\n",
    "\n",
    "    results_df = results_df.groupby(processed_names.LONG_PC_TYPE).agg(\n",
    "        {\"predicted_price\": \"min\", \"actual_price\": \"min\"}\n",
    "    )\n",
    "    results_df[\"date\"] = target_date\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predict_pc_prices(\n",
    "    model=model_6m,\n",
    "    data_df=data,\n",
    "    feature_cols=feature_cols,\n",
    "    data_date=\"2025-04-01\",\n",
    "    target_date=\"2025-10-01\",\n",
    "    predictions_df=multi_preds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_predict_all_pc_prices(\n",
    "    group_by_pc_types: bool, horizon: int, predictions: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Make predictions for all PC prices from July to December 2025.\n",
    "\n",
    "    Args:\n",
    "        group_by_pc_types: Whether to group data by PC types.\n",
    "        horizon: Prediction horizon in months.\n",
    "        predictions: DataFrame containing actual prices for comparison.\n",
    "\n",
    "    Returns: DataFrame with predicted and actual prices for all PCs from\n",
    "             July to December 2025.\n",
    "    \"\"\"\n",
    "    data, _, feature_cols, _ = load_and_prepare_data(\n",
    "        group_by_pc_types=group_by_pc_types, horizon=horizon\n",
    "    )\n",
    "    full_results_df = pd.DataFrame()\n",
    "    for i in range(7, 10):\n",
    "        # Use best 3 month model to predict prices for July, August, September\n",
    "        data_date = f\"2025-0{i - 3}-01\"\n",
    "        target_date = f\"2025-0{i}-01\"\n",
    "        results_df = multi_predict_pc_prices(\n",
    "            model=model_3m,\n",
    "            data_df=data,\n",
    "            feature_cols=feature_cols,\n",
    "            data_date=data_date,\n",
    "            target_date=target_date,\n",
    "            predictions_df=predictions,\n",
    "        )\n",
    "        full_results_df = pd.concat([full_results_df, results_df], axis=0)\n",
    "\n",
    "    for i in range(10, 13):\n",
    "        # Use best 6 month model to predict prices for October, November, December\n",
    "        data_date = f\"2025-0{i - 6}-01\"\n",
    "        target_date = f\"2025-{i}-01\"\n",
    "        results_df = multi_predict_pc_prices(\n",
    "            model=model_6m,\n",
    "            data_df=data,\n",
    "            feature_cols=feature_cols,\n",
    "            data_date=data_date,\n",
    "            target_date=target_date,\n",
    "            predictions_df=predictions,\n",
    "        )\n",
    "        full_results_df = pd.concat([full_results_df, results_df], axis=0)\n",
    "    return full_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = multi_predict_all_pc_prices(\n",
    "    group_by_pc_types=group_by_pc_types, horizon=horizon, predictions=multi_preds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# 5. Visualize Predictions vs Actual Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for visualization\n",
    "viz_df = comparison_df.reset_index()\n",
    "viz_df_melted = viz_df.melt(\n",
    "    id_vars=[\"pc_type\", \"date\"],\n",
    "    value_vars=[\"predicted_price\", \"actual_price\"],\n",
    "    var_name=\"price_type\",\n",
    "    value_name=\"price\",\n",
    ")\n",
    "\n",
    "# Create histogram comparing predicted vs actual prices by date and PC type\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "dates = sorted(viz_df[\"date\"].unique())\n",
    "\n",
    "for idx, date in enumerate(dates):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    date_data = viz_df_melted[viz_df_melted[\"date\"] == date]\n",
    "\n",
    "    # Create grouped bar chart for each PC type\n",
    "    pc_types = sorted(date_data[\"pc_type\"].unique())\n",
    "    x_pos = range(len(pc_types))\n",
    "    width = 0.35\n",
    "\n",
    "    predicted = date_data[date_data[\"price_type\"] == \"predicted_price\"].set_index(\n",
    "        \"pc_type\"\n",
    "    )[\"price\"]\n",
    "    actual = date_data[date_data[\"price_type\"] == \"actual_price\"].set_index(\"pc_type\")[\n",
    "        \"price\"\n",
    "    ]\n",
    "\n",
    "    ax.bar(\n",
    "        [x - width / 2 for x in x_pos],\n",
    "        [predicted.get(pc, 0) for pc in pc_types],\n",
    "        width,\n",
    "        label=\"Our Prediction\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    ax.bar(\n",
    "        [x + width / 2 for x in x_pos],\n",
    "        [actual.get(pc, 0) for pc in pc_types],\n",
    "        width,\n",
    "        label=\"SE Prediction\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"PC Type\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.set_title(f\"Date: {date}\")\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(pc_types, rotation=45, ha=\"right\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\n",
    "    \"Our Predictions vs SE Predictions for PC Prices by Date and PC Type\",\n",
    "    y=1.02,\n",
    "    fontsize=16,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# 6. Compute MAPE (Mean Absolute Percentage Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Calculate MAPE for the entire dataset\n",
    "mape_overall = (\n",
    "    mean_absolute_percentage_error(\n",
    "        comparison_df[\"actual_price\"], comparison_df[\"predicted_price\"]\n",
    "    )\n",
    "    * 100\n",
    ")\n",
    "\n",
    "print(f\"Overall MAPE: {mape_overall:.2f}%\")\n",
    "\n",
    "# Calculate MAPE by PC type\n",
    "mape_by_pc_type = viz_df.groupby(\"pc_type\").apply(\n",
    "    lambda x: mean_absolute_percentage_error(x[\"actual_price\"], x[\"predicted_price\"])\n",
    "    * 100,\n",
    "    include_groups=False,\n",
    ")\n",
    "\n",
    "print(\"\\nMAPE by PC Type:\")\n",
    "for pc_type, mape in mape_by_pc_type.items():\n",
    "    print(f\"  {pc_type}: {mape:.2f}%\")\n",
    "\n",
    "# Calculate MAPE by date\n",
    "mape_by_date = viz_df.groupby(\"date\").apply(\n",
    "    lambda x: mean_absolute_percentage_error(x[\"actual_price\"], x[\"predicted_price\"])\n",
    "    * 100,\n",
    "    include_groups=False,\n",
    ")\n",
    "\n",
    "print(\"\\nMAPE by Date:\")\n",
    "for date, mape in mape_by_date.items():\n",
    "    print(f\"  {date}: {mape:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "14-data-challenge (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
