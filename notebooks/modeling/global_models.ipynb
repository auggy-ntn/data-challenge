{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "The goal of this notebook is to setup a global model training framework, where a single model is trained on all pc types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "\n",
    "from src.modeling.multivariate_model_training import train_global_model\n",
    "\n",
    "load_dotenv()\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress annoying mlflow warning about dependencies\n",
    "# We manage dependencies with uv...\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Failed to resolve installed pip version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# 1. Load and Prepare Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "**See `src/modeling/multivariate_data_prep.py` -> `load_and_prepare_data` for details.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.modeling.multivariate_data_prep import load_and_prepare_data\n",
    "\n",
    "# df, target_col, feature_cols = (\n",
    "# load_and_prepare_data(group_by_pc_types=False, horizon=6)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "We define a function to load data and separate features and target variable from the dataframe. There are different types of features:\n",
    "- Target variable: `pc_price`.\n",
    "- Meta features: `region`, `pc_type` and `date`. (Used for grouping and weighting but not as model features.)\n",
    "- Numerical features: `pc_price_lag_*`, `pc_price_rolling_mean_*`, `regional_avg_price`, `regional_price_volaility_`, `price_deviation_from_regional_avg`, exogenous features like `bpa_capacity_loss_kt` and their lags (less lags than for target), and time features like `month_sin`, `month_cos` and raw `month` or `year`.\n",
    "- Categorical binary features (can keep as is, tree based models handle $0$ and $1$):  `is_recycled`, `is_glass_filled`, `is_flame_retardant`.\n",
    "- Categorical features with multiple categories (Label encoded): `region`, `pc_type`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# 2. Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "**See `src/modeling/multivariate_data_prep.py` -> `adaptive_train_validation_test_split` and `adaptive_train_test_split` for details.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.modeling.multivariate_data_prep import adaptive_train_test_split\n",
    "\n",
    "# train_df, test_df = adaptive_train_test_split(\n",
    "#     df,\n",
    "#     target_test_ratio=0.2,\n",
    "#     min_train_samples=55,\n",
    "#     min_test_samples=20,\n",
    "#     group_by_pc_types=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "For data not grouped by PC types, we can use a standard train-validation-test split. However, since the data is imbalanced across different pc types, we need to ensure that the train set and the test set contain enough samples from each pc type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "For data grouped by PC types, because the data is imbalanced across different pc types, we only perform a train-test split (no validation set). We need to ensure that the train set and the test set contain enough samples from each pc type. This is a problem especially for rare pc types (`gf20` notably). To do this, we use a function that performs an adaptive train-test split, ensuring that each pc type is represented in both sets with a minimum number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# 3. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "**See `src/modeling/multivariate_data_prep.py` -> `prepare_training_data` for details.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Prepare the training, validation and test sets by separating features and target variable, and shift the features and target variable according to the specified history and forecast horizons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# 4. Compute Sample Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "**See `src/modeling/multivariate_data_prep.py` -> `compute_sample_weights` for details.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Because the data is imbalanced across different pc types, we compute sample weights to give more importance to under-represented pc types during model training. This helps the model to learn better representations for these rare pc types. Without this, the model might be biased towards the more common pc types, leading to poor performance on the rare ones. The global performance metric might be good, but the performance on rare pc types would be bad.\n",
    "\n",
    "Additionally, we can also weight samples based on region: we are only concerned about performance in Europe, so we can give more weight to samples from this region. We keep pc types from all regions in the training set to have more data, but we want to prioritize performance on European pc types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# 5. Define evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "**See `src/modeling/evaluation.py` -> `multi_compute_performance_metrics` for details.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "For model evaluation, we will use the Mean Absolute Percentage Error (MAPE) as our primary metric. MAPE is particularly useful in this context because it provides a normalized measure of prediction accuracy, allowing us to assess how well our model performs across different pc types and price ranges. However, using just a global MAPE can be misleading due to the imbalanced nature of the dataset. To address this, we will also compute a weighted MAPE, where each pc type's contribution to the overall metric is weighted inversely proportional to its frequency in the dataset. This approach ensures that the model's performance on rare pc types is adequately represented in the evaluation, preventing the model from being overly optimized for the more common pc types at the expense of the rare ones. We have $3$ metrics in total:\n",
    "- Global MAPE: Overall MAPE across all samples.\n",
    "- Weighted MAPE: MAPE computed with pc type weights.\n",
    "- Per pc type MAPE: MAPE computed for each pc type separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# 6. Train Global Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "**See `src/modeling/multivariate_model_training.py` -> `train_global_model` for details.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "We train a single global model on all pc types using the computed sample weights, and log it to MLflow. This gives us the following training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_global_model(\n",
    "    group_by_pc_types=False,\n",
    "    horizon=3,\n",
    "    use_validation_set=False,\n",
    "    target_test_ratio=0.2,\n",
    "    target_validation_ratio=0.1,\n",
    "    min_train_samples=55,\n",
    "    min_test_samples=20,\n",
    "    min_validation_samples=15,\n",
    "    weighting_method=\"balanced\",\n",
    "    model_type=\"xgboost\",\n",
    "    hyperparameter_grid=None,\n",
    "    mlflow_run_name=\"global_xgboost_model_6m_horizon_no_grouping\",\n",
    "    n_trials=1,\n",
    "    shap_max_display=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "14-data-challenge (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
